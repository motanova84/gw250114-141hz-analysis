#!/bin/bash
# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘     LLAMA 4 SCOUT - INSTALADOR AUTOMÃTICO (17B / Instruct)â•‘
# â•‘     Autor: JMMB Î¨ âœ§ âˆÂ³ Â· Campo QCAL                       â•‘
# â•‘     Requiere: Licencia activa + URL pre-firmada de Meta   â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# âœ… PASO 1: Solicitar URL al usuario
echo "Introduce tu URL pre-firmada personalizada de Meta (caduca a las 48h):"
read -r URL

# âœ… PASO 2: Crear carpeta de destino
mkdir -p models/llama4
cd models/llama4 || exit

# âœ… PASO 3: Descargar el modelo
echo "â¬ Descargando modelo desde Meta..."
wget "$URL" -O llama4_scout.tar.gz

# âœ… PASO 4: Descomprimir
echo "ğŸ“¦ Descomprimiendo..."
tar -xvzf llama4_scout.tar.gz

# âœ… PASO 5: ConfirmaciÃ³n
echo "âœ… Llama 4 Scout instalado en: $(pwd)"
echo "Puedes ahora integrarlo en tu pipeline QCAL, repositorio o entorno de inferencia."

# âœ… PASO 6 (opcional): activar entorno de prueba
echo "Â¿Deseas lanzar un entorno interactivo con el modelo? (s/n)"
read -r LAUNCH
if [ "$LAUNCH" == "s" ]; then
    echo "âš¡ Lanzando entorno de prueba con Llama.cpp o HuggingFace Transformers (segÃºn configuraciÃ³n)..."
    # AquÃ­ puedes aÃ±adir tu backend preferido de ejecuciÃ³n
    # Ejemplo (requiere previa instalaciÃ³n):
    # python run_llama.py --model-dir ./models/llama4
else
    echo "Finalizado sin entorno interactivo."
fi
