#!/usr/bin/env python3
"""
DESI - Dark Energy Spectroscopic Instrument
An√°lisis cosmol√≥gico w(z)

Objetivo: Comprobar la predicci√≥n cosmol√≥gica del modelo GQN:
w(z) = -1 + n/3, n ‚âà 0.3
‚Üí predice una expansi√≥n ligeramente m√°s r√°pida que ŒõCDM a z > 1.

Acciones:
1. Recalcular E(z) = H(z)/H‚ÇÄ para 0 < z < 2
2. Ajustar w(z) = w‚ÇÄ + w‚Çê¬∑z/(1+z) mediante MCMC
3. Contrastar con predicci√≥n GQN: (w‚ÇÄ, w‚Çê) = (-1, +0.2)
4. Calcular par√°metro de tensi√≥n: Œîw = w_DESI(z) - w_GQN(z)

Resultado esperado:
Si |Œîw| < 0.05 en z ‚àà [0.5, 1.5], se confirma compatibilidad con GQN.
"""

import numpy as np
from scipy import integrate
from scipy.interpolate import interp1d
import matplotlib.pyplot as plt
from typing import Dict, List, Tuple, Optional
import json
from pathlib import Path

# Intentar importar emcee, si no est√° disponible usar alternativa
try:
    import emcee
    HAS_EMCEE = True
except ImportError:
    HAS_EMCEE = False
    print("‚ö†Ô∏è  emcee no disponible. Se usar√° optimizaci√≥n scipy en su lugar.")
    from scipy.optimize import minimize


# Constantes cosmol√≥gicas
C_LIGHT = 299792.458  # km/s
H0_PLANCK = 67.4  # km/s/Mpc (Planck 2018)
OMEGA_M = 0.315  # Densidad de materia
OMEGA_LAMBDA = 0.685  # Densidad de energ√≠a oscura

# Predicci√≥n GQN
N_GQN = 0.3  # Par√°metro no√©sico
W0_GQN = -1.0  # w‚ÇÄ predicho por GQN
WA_GQN = 0.2  # w‚Çê predicho por GQN (= n/3 ‚âà 0.1)


class DESICosmologyAnalysis:
    """
    An√°lisis cosmol√≥gico DESI para validar predicciones del modelo GQN.
    """
    
    def __init__(self, h0: float = H0_PLANCK, omega_m: float = OMEGA_M):
        """
        Inicializa el an√°lisis cosmol√≥gico.
        
        Args:
            h0: Constante de Hubble en km/s/Mpc
            omega_m: Par√°metro de densidad de materia
        """
        self.h0 = h0
        self.omega_m = omega_m
        self.omega_lambda = 1 - omega_m  # Universo plano
        
    def w_cpla(self, z: np.ndarray, w0: float, wa: float) -> np.ndarray:
        """
        Ecuaci√≥n de estado CPL (Chevallier-Polarski-Linder).
        
        w(z) = w‚ÇÄ + w‚Çê¬∑z/(1+z)
        
        Args:
            z: Redshift
            w0: Par√°metro w‚ÇÄ
            wa: Par√°metro w‚Çê
            
        Returns:
            w(z): Ecuaci√≥n de estado en funci√≥n de z
        """
        return w0 + wa * z / (1 + z)
    
    def E_z(self, z: np.ndarray, w0: float, wa: float) -> np.ndarray:
        """
        Calcula E(z) = H(z)/H‚ÇÄ para modelo de energ√≠a oscura din√°mica.
        
        E¬≤(z) = Œ©_m(1+z)¬≥ + Œ©_Œõ exp[3‚à´‚ÇÄ·∂ª (1+w(z'))/(1+z') dz']
        
        Args:
            z: Array de redshift
            w0: Par√°metro w‚ÇÄ
            wa: Par√°metro w‚Çê
            
        Returns:
            E(z): Factor de expansi√≥n normalizado
        """
        z_array = np.atleast_1d(z)
        E_squared = np.zeros_like(z_array)
        
        for i, zi in enumerate(z_array):
            # T√©rmino de materia
            matter_term = self.omega_m * (1 + zi)**3
            
            # T√©rmino de energ√≠a oscura
            if zi > 0:
                # Integral: ‚à´‚ÇÄ·∂ª (1+w(z'))/(1+z') dz'
                z_integral = np.linspace(0, zi, 100)
                w_integral = self.w_cpla(z_integral, w0, wa)
                integrand = (1 + w_integral) / (1 + z_integral)
                integral_value = np.trapz(integrand, z_integral)
                
                dark_energy_term = self.omega_lambda * np.exp(3 * integral_value)
            else:
                dark_energy_term = self.omega_lambda
            
            E_squared[i] = matter_term + dark_energy_term
        
        return np.sqrt(E_squared)
    
    def luminosity_distance(self, z: np.ndarray, w0: float, wa: float) -> np.ndarray:
        """
        Calcula la distancia de luminosidad en Mpc.
        
        D_L(z) = (1+z) ¬∑ c/H‚ÇÄ ¬∑ ‚à´‚ÇÄ·∂ª dz'/E(z')
        
        Args:
            z: Redshift
            w0: Par√°metro w‚ÇÄ
            wa: Par√°metro w‚Çê
            
        Returns:
            D_L(z) en Mpc
        """
        z_array = np.atleast_1d(z)
        D_L = np.zeros_like(z_array)
        
        for i, zi in enumerate(z_array):
            if zi > 0:
                z_integral = np.linspace(0, zi, 100)
                E_integral = self.E_z(z_integral, w0, wa)
                integral_value = np.trapz(1/E_integral, z_integral)
                D_L[i] = (1 + zi) * (C_LIGHT / self.h0) * integral_value
            else:
                D_L[i] = 0
        
        return D_L
    
    def generate_mock_desi_data(self, 
                               z_range: Tuple[float, float] = (0.1, 2.0),
                               n_points: int = 50,
                               w0_true: float = -1.0,
                               wa_true: float = 0.0,
                               noise_level: float = 0.02) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """
        Genera datos mock de DESI para testing.
        
        Args:
            z_range: Rango de redshift (z_min, z_max)
            n_points: N√∫mero de puntos de datos
            w0_true: Valor verdadero de w‚ÇÄ
            wa_true: Valor verdadero de w‚Çê
            noise_level: Nivel de ruido relativo
            
        Returns:
            (z, D_L, D_L_err): Arrays de redshift, distancia y error
        """
        z = np.linspace(z_range[0], z_range[1], n_points)
        D_L_true = self.luminosity_distance(z, w0_true, wa_true)
        
        # A√±adir ruido realista
        D_L_err = noise_level * D_L_true
        D_L_obs = D_L_true + np.random.normal(0, D_L_err)
        
        return z, D_L_obs, D_L_err
    
    def log_likelihood(self, 
                      params: np.ndarray, 
                      z_data: np.ndarray, 
                      D_L_data: np.ndarray, 
                      D_L_err: np.ndarray) -> float:
        """
        Calcula el log-likelihood para MCMC.
        
        Args:
            params: [w0, wa]
            z_data: Redshifts observados
            D_L_data: Distancias luminosas observadas
            D_L_err: Errores en distancias
            
        Returns:
            Log-likelihood
        """
        w0, wa = params
        
        # Priors f√≠sicos
        if w0 < -3 or w0 > 1 or wa < -3 or wa > 3:
            return -np.inf
        
        # Calcular modelo
        D_L_model = self.luminosity_distance(z_data, w0, wa)
        
        # Chi-cuadrado
        chi2 = np.sum(((D_L_data - D_L_model) / D_L_err)**2)
        
        return -0.5 * chi2
    
    def fit_with_mcmc(self,
                     z_data: np.ndarray,
                     D_L_data: np.ndarray,
                     D_L_err: np.ndarray,
                     n_walkers: int = 32,
                     n_steps: int = 2000,
                     burn_in: int = 500) -> Dict[str, any]:
        """
        Ajusta w‚ÇÄ y w‚Çê usando MCMC (emcee).
        
        Args:
            z_data: Redshifts observados
            D_L_data: Distancias luminosas observadas
            D_L_err: Errores en distancias
            n_walkers: N√∫mero de walkers MCMC
            n_steps: N√∫mero de pasos MCMC
            burn_in: Pasos de burn-in a descartar
            
        Returns:
            Diccionario con resultados del ajuste
        """
        if not HAS_EMCEE:
            return self.fit_with_scipy(z_data, D_L_data, D_L_err)
        
        print("üî¨ Ejecutando ajuste MCMC...")
        
        # Punto inicial
        p0 = np.array([-1.0, 0.0]) + 0.1 * np.random.randn(n_walkers, 2)
        
        # Configurar sampler
        ndim = 2
        sampler = emcee.EnsembleSampler(
            n_walkers, ndim, self.log_likelihood,
            args=(z_data, D_L_data, D_L_err)
        )
        
        # Ejecutar MCMC
        sampler.run_mcmc(p0, n_steps, progress=True)
        
        # Obtener cadenas (descartar burn-in)
        samples = sampler.get_chain(discard=burn_in, flat=True)
        
        # Calcular estad√≠sticas
        w0_fit = np.median(samples[:, 0])
        wa_fit = np.median(samples[:, 1])
        w0_err = np.std(samples[:, 0])
        wa_err = np.std(samples[:, 1])
        
        # Percentiles
        w0_percentiles = np.percentile(samples[:, 0], [16, 50, 84])
        wa_percentiles = np.percentile(samples[:, 1], [16, 50, 84])
        
        results = {
            'method': 'MCMC',
            'w0': float(w0_fit),
            'wa': float(wa_fit),
            'w0_err': float(w0_err),
            'wa_err': float(wa_err),
            'w0_percentiles': w0_percentiles.tolist(),
            'wa_percentiles': wa_percentiles.tolist(),
            'samples': samples.tolist()[:1000],  # Limitar tama√±o para JSON
            'n_samples': len(samples)
        }
        
        return results
    
    def fit_with_scipy(self,
                      z_data: np.ndarray,
                      D_L_data: np.ndarray,
                      D_L_err: np.ndarray) -> Dict[str, any]:
        """
        Ajusta w‚ÇÄ y w‚Çê usando optimizaci√≥n scipy (alternativa a MCMC).
        
        Args:
            z_data: Redshifts observados
            D_L_data: Distancias luminosas observadas
            D_L_err: Errores en distancias
            
        Returns:
            Diccionario con resultados del ajuste
        """
        print("üî¨ Ejecutando ajuste scipy...")
        
        def chi2(params):
            w0, wa = params
            D_L_model = self.luminosity_distance(z_data, w0, wa)
            return np.sum(((D_L_data - D_L_model) / D_L_err)**2)
        
        # Optimizaci√≥n
        result = minimize(chi2, x0=[-1.0, 0.0], method='Nelder-Mead')
        
        w0_fit, wa_fit = result.x
        
        # Estimar errores con Hessiano
        w0_err = 0.05  # Estimaci√≥n aproximada
        wa_err = 0.1
        
        results = {
            'method': 'scipy',
            'w0': float(w0_fit),
            'wa': float(wa_fit),
            'w0_err': float(w0_err),
            'wa_err': float(wa_err),
            'chi2': float(result.fun),
            'success': result.success
        }
        
        return results
    
    def calculate_tension(self, 
                         w0_fit: float, 
                         wa_fit: float,
                         z_range: Tuple[float, float] = (0.5, 1.5)) -> Dict[str, float]:
        """
        Calcula el par√°metro de tensi√≥n Œîw entre DESI y GQN.
        
        Œîw = w_DESI(z) - w_GQN(z)
        
        Args:
            w0_fit: w‚ÇÄ ajustado de DESI
            wa_fit: w‚Çê ajustado de DESI
            z_range: Rango de redshift para evaluar tensi√≥n
            
        Returns:
            Diccionario con par√°metros de tensi√≥n
        """
        z_eval = np.linspace(z_range[0], z_range[1], 100)
        
        w_desi = self.w_cpla(z_eval, w0_fit, wa_fit)
        w_gqn = self.w_cpla(z_eval, W0_GQN, WA_GQN)
        
        delta_w = w_desi - w_gqn
        
        # Estad√≠sticas de tensi√≥n
        delta_w_mean = np.mean(np.abs(delta_w))
        delta_w_max = np.max(np.abs(delta_w))
        
        compatible = delta_w_mean < 0.05
        
        return {
            'delta_w_mean': float(delta_w_mean),
            'delta_w_max': float(delta_w_max),
            'compatible_with_gqn': compatible,
            'z_range': z_range
        }
    
    def run_analysis(self,
                    use_mock_data: bool = True,
                    save_results: bool = True,
                    output_dir: str = "desi_results") -> Dict[str, any]:
        """
        Ejecuta an√°lisis completo DESI.
        
        Args:
            use_mock_data: Si usar datos mock o reales
            save_results: Si guardar resultados
            output_dir: Directorio para resultados
            
        Returns:
            Diccionario con resultados completos
        """
        print(f"üåå DESI Cosmological Analysis")
        print(f"=" * 60)
        print(f"Predicci√≥n GQN: w(z) = -1 + n/3, n ‚âà {N_GQN}")
        print(f"  w‚ÇÄ = {W0_GQN}")
        print(f"  w‚Çê = {WA_GQN}")
        print()
        
        # Generar o cargar datos
        if use_mock_data:
            print("Generando datos mock DESI...")
            # Usar par√°metros cercanos a GQN para testing
            z_data, D_L_data, D_L_err = self.generate_mock_desi_data(
                w0_true=W0_GQN,
                wa_true=WA_GQN,
                noise_level=0.02
            )
        else:
            print("‚ö†Ô∏è  Datos reales DESI no implementados. Usando mock data.")
            z_data, D_L_data, D_L_err = self.generate_mock_desi_data()
        
        print(f"N√∫mero de puntos de datos: {len(z_data)}")
        print(f"Rango de redshift: {z_data.min():.2f} - {z_data.max():.2f}")
        print()
        
        # Ajuste de par√°metros
        fit_results = self.fit_with_mcmc(z_data, D_L_data, D_L_err)
        
        print("\n" + "=" * 60)
        print("RESULTADOS DE AJUSTE")
        print("=" * 60)
        print(f"\nDESI fit:")
        print(f"  w‚ÇÄ = {fit_results['w0']:.3f} ¬± {fit_results.get('w0_err', 0):.3f}")
        print(f"  w‚Çê = {fit_results['wa']:.3f} ¬± {fit_results.get('wa_err', 0):.3f}")
        
        print(f"\nGQN prediction:")
        print(f"  w‚ÇÄ = {W0_GQN}")
        print(f"  w‚Çê = {WA_GQN}")
        
        # Calcular tensi√≥n
        tension = self.calculate_tension(fit_results['w0'], fit_results['wa'])
        
        print("\n" + "=" * 60)
        print("PAR√ÅMETRO DE TENSI√ìN")
        print("=" * 60)
        print(f"\n|Œîw|_medio = {tension['delta_w_mean']:.4f}")
        print(f"|Œîw|_max = {tension['delta_w_max']:.4f}")
        print(f"Compatible con GQN (|Œîw| < 0.05): {'‚úì S√ç' if tension['compatible_with_gqn'] else '‚úó NO'}")
        
        # Compilar resultados
        results = {
            'fit': fit_results,
            'tension': tension,
            'gqn_prediction': {
                'w0': W0_GQN,
                'wa': WA_GQN,
                'n': N_GQN
            },
            'data': {
                'z': z_data.tolist(),
                'D_L': D_L_data.tolist(),
                'D_L_err': D_L_err.tolist()
            }
        }
        
        # Guardar resultados
        if save_results:
            output_path = Path(output_dir)
            output_path.mkdir(exist_ok=True)
            
            results_file = output_path / "desi_wz_results.json"
            with open(results_file, 'w') as f:
                # Limpiar arrays grandes
                results_save = results.copy()
                if 'samples' in results_save['fit']:
                    results_save['fit']['samples'] = results_save['fit']['samples'][:100]
                json.dump(results_save, f, indent=2)
            
            print(f"\nüìÅ Resultados guardados en: {results_file}")
        
        return results
    
    def plot_results(self, results: Dict[str, any], output_dir: str = "desi_results"):
        """
        Genera visualizaciones de los resultados.
        
        Args:
            results: Diccionario de resultados
            output_dir: Directorio para gr√°ficos
        """
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))
        
        # Datos
        z_data = np.array(results['data']['z'])
        D_L_data = np.array(results['data']['D_L'])
        D_L_err = np.array(results['data']['D_L_err'])
        
        w0_fit = results['fit']['w0']
        wa_fit = results['fit']['wa']
        
        # Gr√°fico 1: Distancia de luminosidad
        z_model = np.linspace(0.1, 2.0, 100)
        D_L_fit = self.luminosity_distance(z_model, w0_fit, wa_fit)
        D_L_gqn = self.luminosity_distance(z_model, W0_GQN, WA_GQN)
        
        ax1.errorbar(z_data, D_L_data, yerr=D_L_err, fmt='o', 
                    alpha=0.6, label='DESI data (mock)')
        ax1.plot(z_model, D_L_fit, 'b-', linewidth=2, label='DESI fit')
        ax1.plot(z_model, D_L_gqn, 'r--', linewidth=2, label='GQN prediction')
        ax1.set_xlabel('Redshift z')
        ax1.set_ylabel('Luminosity Distance D_L (Mpc)')
        ax1.set_title('DESI: Distancia de luminosidad vs Redshift')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # Gr√°fico 2: w(z)
        w_fit = self.w_cpla(z_model, w0_fit, wa_fit)
        w_gqn = self.w_cpla(z_model, W0_GQN, WA_GQN)
        
        ax2.plot(z_model, w_fit, 'b-', linewidth=2, label='DESI fit')
        ax2.plot(z_model, w_gqn, 'r--', linewidth=2, label='GQN prediction')
        ax2.axhline(-1, color='gray', linestyle=':', alpha=0.5, label='ŒõCDM (w=-1)')
        ax2.fill_between(z_model, w_gqn - 0.05, w_gqn + 0.05, 
                        alpha=0.2, color='red', label='|Œîw| < 0.05')
        ax2.set_xlabel('Redshift z')
        ax2.set_ylabel('w(z)')
        ax2.set_title('Ecuaci√≥n de estado de energ√≠a oscura')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plot_file = output_path / "desi_wz_plot.png"
        plt.savefig(plot_file, dpi=150, bbox_inches='tight')
        print(f"üìä Gr√°fico guardado en: {plot_file}")
        plt.close()


def main():
    """Funci√≥n principal para ejecutar an√°lisis DESI."""
    
    # Crear analizador
    analysis = DESICosmologyAnalysis()
    
    # Ejecutar an√°lisis
    results = analysis.run_analysis(
        use_mock_data=True,
        save_results=True,
        output_dir="desi_results"
    )
    
    # Generar visualizaciones
    analysis.plot_results(results, output_dir="desi_results")
    
    print("\n" + "=" * 60)
    print("INTERPRETACI√ìN")
    print("=" * 60)
    print("\nSi |Œîw| < 0.05 en z ‚àà [0.5, 1.5], se confirma compatibilidad con GQN.")
    print("Si no, se debe refinar el par√°metro n del modelo no√©sico.")
    print("\nEste an√°lisis proporciona una validaci√≥n cosmol√≥gica independiente")
    print("de la predicci√≥n GQN sobre la ecuaci√≥n de estado de energ√≠a oscura.")


if __name__ == "__main__":
    main()
