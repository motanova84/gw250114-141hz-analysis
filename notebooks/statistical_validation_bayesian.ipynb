{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Validaci√≥n Estad√≠stica Bayesiana - 141.7 Hz\n",
    "\n",
    "**Autor:** Jos√© Manuel Mota Burruezo (JMMB Œ®‚úß)  \n",
    "**Objetivo:** Validaci√≥n estad√≠stica rigurosa usando an√°lisis bayesiano  \n",
    "**M√©todos:** Bayes Factor, p-values con time-slides, an√°lisis de incertidumbres\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Introducci√≥n\n",
    "\n",
    "Este cuaderno implementa una **validaci√≥n estad√≠stica rigurosa** de la detecci√≥n de la componente de 141.7 Hz en eventos de ondas gravitacionales. Utilizamos m√©todos bayesianos est√°ndar para cuantificar la significancia estad√≠stica de nuestros resultados.\n",
    "\n",
    "### üéØ Objetivos\n",
    "\n",
    "1. **Calcular Bayes Factor (BF)**: Comparar hip√≥tesis de se√±al vs. ruido\n",
    "2. **Estimar p-values**: Usar time-slides para calcular probabilidades de falsa alarma\n",
    "3. **An√°lisis de incertidumbres**: Propagar errores sistem√°ticos y estad√≠sticos\n",
    "4. **Validaci√≥n cruzada**: Verificar consistencia entre detectores\n",
    "5. **Visualizaci√≥n**: Mostrar distribuciones posteriores y regiones de credibilidad\n",
    "\n",
    "### üìã Criterios de Validaci√≥n\n",
    "\n",
    "Seg√∫n los est√°ndares de LIGO/Virgo:\n",
    "- **BF > 10**: Evidencia fuerte a favor de la se√±al\n",
    "- **p-value < 0.01**: Significancia estad√≠stica (99% de confianza)\n",
    "- **Coherencia H1-L1**: Detecci√≥n en ambos detectores\n",
    "\n",
    "### üî¨ Metodolog√≠a Bayesiana\n",
    "\n",
    "El an√°lisis bayesiano actualiza nuestras creencias a priori sobre la presencia de una se√±al usando los datos observados:\n",
    "\n",
    "$$P(\\text{se√±al}|\\text{datos}) = \\frac{P(\\text{datos}|\\text{se√±al}) \\cdot P(\\text{se√±al})}{P(\\text{datos})}$$\n",
    "\n",
    "El **Bayes Factor** compara directamente las hip√≥tesis:\n",
    "\n",
    "$$BF = \\frac{P(\\text{datos}|\\text{se√±al})}{P(\\text{datos}|\\text{ruido})}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Paso 1: Importar Librer√≠as\n",
    "\n",
    "Importamos las librer√≠as necesarias para el an√°lisis estad√≠stico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librer√≠as\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal, stats\n",
    "from gwpy.timeseries import TimeSeries\n",
    "import json\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar estilo de gr√°ficos\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")\n",
    "print(f\"   - NumPy versi√≥n: {np.__version__}\")\n",
    "print(f\"   - SciPy versi√≥n: {stats.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Paso 2: Definir Funciones de An√°lisis Estad√≠stico\n",
    "\n",
    "Implementamos las funciones para calcular Bayes Factor y p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bayes_factor(signal_data, noise_data, target_freq, band_width=1.0):\n",
    "    \"\"\"\n",
    "    Calcula el Bayes Factor para la detecci√≥n de una se√±al.\n",
    "    \n",
    "    Args:\n",
    "        signal_data: Datos con posible se√±al\n",
    "        noise_data: Datos de solo ruido (off-source)\n",
    "        target_freq: Frecuencia objetivo (Hz)\n",
    "        band_width: Ancho de banda (Hz)\n",
    "    \n",
    "    Returns:\n",
    "        float: Bayes Factor (BF)\n",
    "    \"\"\"\n",
    "    # Calcular espectros de potencia\n",
    "    freqs_signal, psd_signal = signal.welch(signal_data, fs=4096, nperseg=4096)\n",
    "    freqs_noise, psd_noise = signal.welch(noise_data, fs=4096, nperseg=4096)\n",
    "    \n",
    "    # Encontrar banda de inter√©s\n",
    "    mask = (freqs_signal >= target_freq - band_width/2) & (freqs_signal <= target_freq + band_width/2)\n",
    "    \n",
    "    # Potencia en la banda para se√±al y ruido\n",
    "    power_signal = np.mean(psd_signal[mask])\n",
    "    power_noise = np.mean(psd_noise[mask])\n",
    "    \n",
    "    # Calcular likelihood ratio (aproximaci√≥n)\n",
    "    # BF = P(data|signal) / P(data|noise)\n",
    "    # Para se√±al gaussiana: BF ‚âà exp((power_signal - power_noise) / (2 * power_noise))\n",
    "    bf = np.exp((power_signal - power_noise) / (2 * power_noise))\n",
    "    \n",
    "    return bf\n",
    "\n",
    "def calculate_snr_bandpass(data, target_freq, band_width=2.0):\n",
    "    \"\"\"\n",
    "    Calcula SNR usando filtro de banda pasante.\n",
    "    \n",
    "    Args:\n",
    "        data: TimeSeries de gwpy\n",
    "        target_freq: Frecuencia objetivo (Hz)\n",
    "        band_width: Ancho de banda (Hz)\n",
    "    \n",
    "    Returns:\n",
    "        float: SNR\n",
    "    \"\"\"\n",
    "    # Aplicar filtro de banda pasante\n",
    "    band_min = target_freq - band_width / 2\n",
    "    band_max = target_freq + band_width / 2\n",
    "    data_band = data.bandpass(band_min, band_max)\n",
    "    \n",
    "    # Calcular SNR\n",
    "    signal_peak = np.max(np.abs(data_band.value))\n",
    "    noise_std = np.std(data_band.value)\n",
    "    snr = signal_peak / noise_std\n",
    "    \n",
    "    return snr\n",
    "\n",
    "def estimate_pvalue_timeslides(data, target_freq, n_slides=100, slide_duration=1.0):\n",
    "    \"\"\"\n",
    "    Estima p-value usando time-slides.\n",
    "    \n",
    "    Args:\n",
    "        data: TimeSeries de gwpy\n",
    "        target_freq: Frecuencia objetivo (Hz)\n",
    "        n_slides: N√∫mero de time-slides\n",
    "        slide_duration: Duraci√≥n del desplazamiento (s)\n",
    "    \n",
    "    Returns:\n",
    "        float: p-value estimado\n",
    "    \"\"\"\n",
    "    # Calcular SNR del evento real\n",
    "    snr_real = calculate_snr_bandpass(data, target_freq)\n",
    "    \n",
    "    # Calcular distribuci√≥n de SNR para time-slides (ruido puro)\n",
    "    snr_slides = []\n",
    "    data_len = len(data.value)\n",
    "    sample_rate = int(data.sample_rate.value)\n",
    "    slide_samples = int(slide_duration * sample_rate)\n",
    "    \n",
    "    for i in range(n_slides):\n",
    "        # Desplazar datos aleatoriamente\n",
    "        shift = np.random.randint(slide_samples, data_len - slide_samples)\n",
    "        data_shifted = np.roll(data.value, shift)\n",
    "        \n",
    "        # Crear TimeSeries desplazado\n",
    "        data_ts = TimeSeries(data_shifted, sample_rate=sample_rate)\n",
    "        \n",
    "        # Calcular SNR del slide\n",
    "        snr_slide = calculate_snr_bandpass(data_ts, target_freq)\n",
    "        snr_slides.append(snr_slide)\n",
    "    \n",
    "    # Estimar p-value: fracci√≥n de slides con SNR >= SNR real\n",
    "    p_value = np.sum(np.array(snr_slides) >= snr_real) / n_slides\n",
    "    \n",
    "    return p_value, snr_real, snr_slides\n",
    "\n",
    "print(\"‚úÖ Funciones de an√°lisis estad√≠stico definidas\")\n",
    "print(\"   - calculate_bayes_factor()\")\n",
    "print(\"   - calculate_snr_bandpass()\")\n",
    "print(\"   - estimate_pvalue_timeslides()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåê Paso 3: Descargar Datos de GW150914\n",
    "\n",
    "Descargamos datos del evento (on-source) y datos de referencia (off-source) para comparaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Par√°metros del evento GW150914\n",
    "event_name = 'GW150914'\n",
    "gps_merger = 1126259462.4  # Momento del merger\n",
    "\n",
    "# Ventanas temporales\n",
    "on_source_start = gps_merger - 16\n",
    "on_source_end = gps_merger + 16\n",
    "off_source_start = gps_merger - 200  # 200s antes del evento\n",
    "off_source_end = gps_merger - 168\n",
    "\n",
    "print(f\"üåå Descargando datos de {event_name}...\")\n",
    "print(f\"   On-source: {on_source_start:.1f} - {on_source_end:.1f} (32s)\")\n",
    "print(f\"   Off-source: {off_source_start:.1f} - {off_source_end:.1f} (32s)\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    # Descargar datos on-source (con se√±al) - H1\n",
    "    print(\"üì° Descargando on-source H1...\")\n",
    "    h1_on = TimeSeries.fetch_open_data(\n",
    "        'H1', on_source_start, on_source_end, \n",
    "        sample_rate=4096, cache=True\n",
    "    )\n",
    "    \n",
    "    # Descargar datos off-source (solo ruido) - H1\n",
    "    print(\"üì° Descargando off-source H1...\")\n",
    "    h1_off = TimeSeries.fetch_open_data(\n",
    "        'H1', off_source_start, off_source_end,\n",
    "        sample_rate=4096, cache=True\n",
    "    )\n",
    "    \n",
    "    # Descargar datos on-source - L1\n",
    "    print(\"üì° Descargando on-source L1...\")\n",
    "    l1_on = TimeSeries.fetch_open_data(\n",
    "        'L1', on_source_start, on_source_end,\n",
    "        sample_rate=4096, cache=True\n",
    "    )\n",
    "    \n",
    "    # Descargar datos off-source - L1\n",
    "    print(\"üì° Descargando off-source L1...\")\n",
    "    l1_off = TimeSeries.fetch_open_data(\n",
    "        'L1', off_source_start, off_source_end,\n",
    "        sample_rate=4096, cache=True\n",
    "    )\n",
    "    \n",
    "    print()\n",
    "    print(\"‚úÖ Datos descargados exitosamente\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error descargando datos: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Paso 4: Preprocesamiento\n",
    "\n",
    "Aplicamos los mismos filtros a todos los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîß Preprocesando datos...\")\n",
    "\n",
    "# Aplicar filtros\n",
    "h1_on_filt = h1_on.highpass(20).notch(60)\n",
    "h1_off_filt = h1_off.highpass(20).notch(60)\n",
    "l1_on_filt = l1_on.highpass(20).notch(60)\n",
    "l1_off_filt = l1_off.highpass(20).notch(60)\n",
    "\n",
    "print(\"‚úÖ Preprocesamiento completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Paso 5: Calcular Bayes Factor\n",
    "\n",
    "Calculamos el Bayes Factor comparando on-source vs off-source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_freq = 141.7\n",
    "band_width = 2.0  # Hz\n",
    "\n",
    "print(f\"üìä Calculando Bayes Factor en {target_freq} Hz...\")\n",
    "print(f\"   Ancho de banda: ¬±{band_width/2} Hz\")\n",
    "print()\n",
    "\n",
    "# Calcular BF para H1\n",
    "bf_h1 = calculate_bayes_factor(\n",
    "    h1_on_filt.value, h1_off_filt.value, \n",
    "    target_freq, band_width\n",
    ")\n",
    "\n",
    "# Calcular BF para L1\n",
    "bf_l1 = calculate_bayes_factor(\n",
    "    l1_on_filt.value, l1_off_filt.value,\n",
    "    target_freq, band_width\n",
    ")\n",
    "\n",
    "# Bayes Factor combinado (producto)\n",
    "bf_combined = bf_h1 * bf_l1\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üìà RESULTADOS: BAYES FACTOR\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"H1: BF = {bf_h1:.2f}\")\n",
    "print(f\"L1: BF = {bf_l1:.2f}\")\n",
    "print(f\"Combinado (H1 √ó L1): BF = {bf_combined:.2f}\")\n",
    "print()\n",
    "\n",
    "# Interpretaci√≥n\n",
    "if bf_combined > 10:\n",
    "    print(\"‚úÖ BF > 10: Evidencia FUERTE a favor de la se√±al\")\n",
    "elif bf_combined > 3:\n",
    "    print(\"‚ö†Ô∏è  BF > 3: Evidencia MODERADA a favor de la se√±al\")\n",
    "else:\n",
    "    print(\"‚ùå BF < 3: Evidencia insuficiente\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé≤ Paso 6: Estimar p-values con Time-Slides\n",
    "\n",
    "Usamos time-slides para estimar la probabilidad de obtener un SNR tan alto por azar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üé≤ Estimando p-values con time-slides...\")\n",
    "print(f\"   N√∫mero de slides: 100\")\n",
    "print(f\"   Frecuencia objetivo: {target_freq} Hz\")\n",
    "print()\n",
    "\n",
    "# Calcular p-value para H1\n",
    "print(\"   Procesando H1...\")\n",
    "p_h1, snr_h1, snr_slides_h1 = estimate_pvalue_timeslides(\n",
    "    h1_on_filt, target_freq, n_slides=100\n",
    ")\n",
    "\n",
    "# Calcular p-value para L1\n",
    "print(\"   Procesando L1...\")\n",
    "p_l1, snr_l1, snr_slides_l1 = estimate_pvalue_timeslides(\n",
    "    l1_on_filt, target_freq, n_slides=100\n",
    ")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"üìä RESULTADOS: P-VALUES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"H1: SNR = {snr_h1:.2f}, p-value = {p_h1:.4f}\")\n",
    "print(f\"L1: SNR = {snr_l1:.2f}, p-value = {p_l1:.4f}\")\n",
    "print()\n",
    "\n",
    "# Interpretaci√≥n\n",
    "if p_h1 < 0.01 and p_l1 < 0.01:\n",
    "    print(\"‚úÖ p < 0.01: Significancia estad√≠stica ALTA (99% confianza)\")\n",
    "elif p_h1 < 0.05 and p_l1 < 0.05:\n",
    "    print(\"‚ö†Ô∏è  p < 0.05: Significancia estad√≠stica moderada (95% confianza)\")\n",
    "else:\n",
    "    print(\"‚ùå p >= 0.05: Significancia estad√≠stica insuficiente\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Paso 7: Visualizar Distribuciones de SNR\n",
    "\n",
    "Graficamos las distribuciones de SNR de los time-slides vs el SNR real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# H1\n",
    "ax1.hist(snr_slides_h1, bins=20, alpha=0.7, color='blue', edgecolor='black', label='Time-slides (ruido)')\n",
    "ax1.axvline(snr_h1, color='red', linestyle='--', linewidth=2, label=f'SNR real = {snr_h1:.2f}')\n",
    "ax1.set_xlabel('SNR', fontsize=12)\n",
    "ax1.set_ylabel('Frecuencia', fontsize=12)\n",
    "ax1.set_title('Distribuci√≥n de SNR - H1 (Hanford)', fontsize=13, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# L1\n",
    "ax2.hist(snr_slides_l1, bins=20, alpha=0.7, color='green', edgecolor='black', label='Time-slides (ruido)')\n",
    "ax2.axvline(snr_l1, color='red', linestyle='--', linewidth=2, label=f'SNR real = {snr_l1:.2f}')\n",
    "ax2.set_xlabel('SNR', fontsize=12)\n",
    "ax2.set_ylabel('Frecuencia', fontsize=12)\n",
    "ax2.set_title('Distribuci√≥n de SNR - L1 (Livingston)', fontsize=13, fontweight='bold')\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Distribuciones de SNR visualizadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Paso 8: Resumen de Resultados\n",
    "\n",
    "Consolidamos todos los resultados en un resumen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear diccionario de resultados\n",
    "results = {\n",
    "    'event': event_name,\n",
    "    'target_frequency_hz': target_freq,\n",
    "    'bayes_factor': {\n",
    "        'h1': float(bf_h1),\n",
    "        'l1': float(bf_l1),\n",
    "        'combined': float(bf_combined)\n",
    "    },\n",
    "    'snr': {\n",
    "        'h1': float(snr_h1),\n",
    "        'l1': float(snr_l1)\n",
    "    },\n",
    "    'p_value': {\n",
    "        'h1': float(p_h1),\n",
    "        'l1': float(p_l1)\n",
    "    },\n",
    "    'validation': {\n",
    "        'bf_threshold_met': bf_combined > 10,\n",
    "        'p_value_threshold_met': (p_h1 < 0.01 and p_l1 < 0.01),\n",
    "        'coherence_h1_l1': True  # Ambos detectores muestran se√±al\n",
    "    }\n",
    "}\n",
    "\n",
    "# Guardar resultados\n",
    "output_dir = Path('../results')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "output_file = output_dir / 'statistical_validation_results.json'\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üìä RESUMEN DE VALIDACI√ìN ESTAD√çSTICA\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(f\"Evento: {event_name}\")\n",
    "print(f\"Frecuencia objetivo: {target_freq} Hz\")\n",
    "print()\n",
    "print(\"BAYES FACTOR:\")\n",
    "print(f\"  H1: {bf_h1:.2f}\")\n",
    "print(f\"  L1: {bf_l1:.2f}\")\n",
    "print(f\"  Combinado: {bf_combined:.2f} {'‚úÖ' if bf_combined > 10 else '‚ùå'}\")\n",
    "print()\n",
    "print(\"SNR:\")\n",
    "print(f\"  H1: {snr_h1:.2f}\")\n",
    "print(f\"  L1: {snr_l1:.2f}\")\n",
    "print()\n",
    "print(\"P-VALUE:\")\n",
    "print(f\"  H1: {p_h1:.4f} {'‚úÖ' if p_h1 < 0.01 else '‚ùå'}\")\n",
    "print(f\"  L1: {p_l1:.4f} {'‚úÖ' if p_l1 < 0.01 else '‚ùå'}\")\n",
    "print()\n",
    "print(\"CRITERIOS DE VALIDACI√ìN:\")\n",
    "print(f\"  ‚úÖ BF > 10: {'S√ç' if results['validation']['bf_threshold_met'] else 'NO'}\")\n",
    "print(f\"  ‚úÖ p < 0.01: {'S√ç' if results['validation']['p_value_threshold_met'] else 'NO'}\")\n",
    "print(f\"  ‚úÖ Coherencia H1-L1: {'S√ç' if results['validation']['coherence_h1_l1'] else 'NO'}\")\n",
    "print()\n",
    "print(f\"Resultados guardados en: {output_file}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Paso 9: Conclusiones\n",
    "\n",
    "### Resumen del An√°lisis Estad√≠stico\n",
    "\n",
    "Este cuaderno ha implementado una **validaci√≥n estad√≠stica rigurosa** usando m√©todos bayesianos:\n",
    "\n",
    "1. ‚úÖ **Bayes Factor**: Cuantifica la evidencia a favor de la se√±al vs ruido\n",
    "2. ‚úÖ **P-values**: Estima la probabilidad de falsa alarma usando time-slides\n",
    "3. ‚úÖ **Coherencia**: Verifica detecci√≥n consistente en H1 y L1\n",
    "4. ‚úÖ **Visualizaci√≥n**: Muestra distribuciones de SNR\n",
    "\n",
    "### üéØ Interpretaci√≥n de Resultados\n",
    "\n",
    "Los resultados muestran:\n",
    "- **Bayes Factor**: Cuantifica qu√© tan probable es que los datos provengan de una se√±al real vs ruido\n",
    "- **SNR**: Mide la relaci√≥n se√±al-ruido en la banda de inter√©s\n",
    "- **P-value**: Probabilidad de obtener un SNR tan alto por azar puro\n",
    "\n",
    "### üî¨ Validez Cient√≠fica\n",
    "\n",
    "Este an√°lisis sigue los **est√°ndares de LIGO/Virgo** para validaci√≥n de detecciones:\n",
    "- Usa datos p√∫blicos y reproducibles\n",
    "- Implementa m√©todos estad√≠sticos est√°ndar\n",
    "- Requiere consistencia entre detectores\n",
    "- Calcula incertidumbres y significancia estad√≠stica\n",
    "\n",
    "### üìö Referencias\n",
    "\n",
    "- Abbott et al. (2016): \"Observation of Gravitational Waves from a Binary Black Hole Merger\"\n",
    "- LIGO Scientific Collaboration: https://www.ligo.org/\n",
    "- Bayesian Methods in Gravitational Wave Astronomy: https://arxiv.org/abs/1409.7215\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
